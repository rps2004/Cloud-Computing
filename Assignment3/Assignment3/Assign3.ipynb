{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V5E1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "Cg6IG4dRlnba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KH5SPlIgNUlP"
      },
      "outputs": [],
      "source": [
        "# CELL 1: Settings / Device selection\n",
        "# Change DEVICE to \"CPU\", \"GPU\", or \"TPU\" before running. Set runtime in Colab accordingly.\n",
        "DEVICE = \"TPU\"   # \"CPU\" | \"GPU\" | \"TPU\"\n",
        "\n",
        "# Basic params (edit paths after mounting)\n",
        "CSV_TRAIN_PATH = \"/content/drive/MyDrive/train.csv\"   # path to train.csv in Drive\n",
        "CSV_TEST_PATH  = \"/content/drive/MyDrive/test.csv\"    # path to test.csv in Drive\n",
        "RESULTS_DIR = f\"/content/drive/MyDrive/taxi_results_{DEVICE}\"\n",
        "SAMPLE_SIZE = 500000\n",
        "CHUNK_SIZE = 500000\n",
        "RANDOM_SEED = 42\n",
        "EPOCHS = 25\n",
        "BATCH_SIZE = 1024      # increase for GPU/TPU; TPU may require multiples of 8/128\n",
        "TEST_SPLIT = 0.1\n",
        "\n",
        "import os, time, math\n",
        "import numpy as np, pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, callbacks\n",
        "\n",
        "np.random.seed(RANDOM_SEED)\n",
        "tf.random.set_seed(RANDOM_SEED)\n",
        "\n",
        "# Device hints\n",
        "if DEVICE == \"CPU\":\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"   # hide GPU\n",
        "    print(\"Running CPU-only.\")\n",
        "elif DEVICE == \"GPU\":\n",
        "    print(\"Running on GPU. Ensure Colab runtime -> GPU is selected.\")\n",
        "elif DEVICE == \"TPU\":\n",
        "    print(\"TPU requested. Ensure Colab runtime -> TPU is selected.\")\n",
        "else:\n",
        "    raise ValueError(\"DEVICE must be one of 'CPU','GPU','TPU'.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 2: Mount Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "print(\"Results directory:\", RESULTS_DIR)\n"
      ],
      "metadata": {
        "id": "9MnFG8RMNVtQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 3: TPU init (run but harmless on non-TPU)\n",
        "strategy = tf.distribute.get_strategy()\n",
        "if DEVICE == \"TPU\":\n",
        "    try:\n",
        "        resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "        tf.config.experimental_connect_to_cluster(resolver)\n",
        "        tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "        strategy = tf.distribute.TPUStrategy(resolver)\n",
        "        print(\"TPU initialized. Strategy:\", type(strategy))\n",
        "        # adjust batch size recommendation\n",
        "        if BATCH_SIZE < 2048:\n",
        "            print(\"Consider increasing BATCH_SIZE for TPU (e.g., 4096)\")\n",
        "    except Exception as e:\n",
        "        print(\"TPU init failed, falling back to default strategy:\", e)\n",
        "        strategy = tf.distribute.get_strategy()\n",
        "else:\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "print(\"Using strategy:\", type(strategy))\n"
      ],
      "metadata": {
        "id": "bp1V32sCNlST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === FIXED MINIMAL preprocess_df (no filtering, no row dropping) ===\n",
        "\n",
        "def preprocess_df(df):\n",
        "    df = df.copy()\n",
        "\n",
        "\n",
        "    # --- Add missing fare_amount for TEST ---\n",
        "    if 'fare_amount' not in df.columns:\n",
        "        df['fare_amount'] = 0   # placeholder for test rows\n",
        "    # --- 1. Datetime features ---\n",
        "    if 'pickup_datetime' in df.columns:\n",
        "        df['pickup_datetime'] = pd.to_datetime(df['pickup_datetime'], errors='coerce')\n",
        "        df['hour'] = df['pickup_datetime'].dt.hour.fillna(0).astype(int)\n",
        "        df['dow']  = df['pickup_datetime'].dt.dayofweek.fillna(0).astype(int)\n",
        "        df['month']= df['pickup_datetime'].dt.month.fillna(0).astype(int)\n",
        "    else:\n",
        "        df['hour'] = 0\n",
        "        df['dow'] = 0\n",
        "        df['month'] = 0\n",
        "\n",
        "    # --- 2. Convert numeric columns (but DO NOT drop rows if invalid) ---\n",
        "    num_cols = ['pickup_longitude','pickup_latitude',\n",
        "                'dropoff_longitude','dropoff_latitude',\n",
        "                'passenger_count','fare_amount']\n",
        "    for c in num_cols:\n",
        "        if c in df.columns:\n",
        "            df[c] = pd.to_numeric(df[c], errors='coerce')\n",
        "\n",
        "    # Fill missing numeric values with 0 (or fallback)\n",
        "    df[num_cols] = df[num_cols].fillna(0)\n",
        "\n",
        "    # --- 3. Compute distance (NaNs handled because we filled above) ---\n",
        "    R = 6371.0\n",
        "    φ1 = np.radians(df['pickup_latitude'])\n",
        "    φ2 = np.radians(df['dropoff_latitude'])\n",
        "    Δφ = np.radians(df['dropoff_latitude'] - df['pickup_latitude'])\n",
        "    Δλ = np.radians(df['dropoff_longitude'] - df['pickup_longitude'])\n",
        "    a = np.sin(Δφ/2)**2 + np.cos(φ1) * np.cos(φ2) * np.sin(Δλ/2)**2\n",
        "    df['distance_km'] = R * 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
        "\n",
        "    # --- 4. Simple additional diffs ---\n",
        "    df['abs_lon_diff'] = (df['pickup_longitude'] - df['dropoff_longitude']).abs()\n",
        "    df['abs_lat_diff'] = (df['pickup_latitude'] - df['dropoff_latitude']).abs()\n",
        "\n",
        "    # --- 5. Passenger count ---\n",
        "    df['passenger_count'] = df['passenger_count'].astype(int).clip(0, 10)\n",
        "\n",
        "    # --- 6. FEATURES ---\n",
        "    features = [\n",
        "        'hour','dow','month',\n",
        "        'pickup_longitude','pickup_latitude',\n",
        "        'dropoff_longitude','dropoff_latitude',\n",
        "        'distance_km','abs_lon_diff','abs_lat_diff',\n",
        "        'passenger_count'\n",
        "    ]\n",
        "\n",
        "    # keep ALL rows\n",
        "    X = df[features]\n",
        "\n",
        "    # Target (only present in train)\n",
        "    y = df['fare_amount'] if 'fare_amount' in df.columns else pd.Series(np.zeros(len(df)))\n",
        "\n",
        "    return X, y\n"
      ],
      "metadata": {
        "id": "T952bIUzNm8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 5: Load sampled training data (stream chunks)\n",
        "def load_sampled_dataframe(csv_path, sample_size=SAMPLE_SIZE, chunk_size=CHUNK_SIZE):\n",
        "    reader = pd.read_csv(csv_path, chunksize=chunk_size, iterator=True)\n",
        "    feats, tars = [], []\n",
        "    total = 0\n",
        "    for chunk in reader:\n",
        "        Xc, yc = preprocess_df(chunk)\n",
        "        if len(Xc)==0:\n",
        "            continue\n",
        "        if sample_size > 0:\n",
        "            remaining = sample_size - total\n",
        "            if remaining <= 0:\n",
        "                break\n",
        "            if len(Xc) > remaining:\n",
        "                sel = Xc.sample(n=remaining, random_state=RANDOM_SEED)\n",
        "                feats.append(sel)\n",
        "                tars.append(yc.loc[sel.index])\n",
        "                total += remaining\n",
        "                break\n",
        "            else:\n",
        "                feats.append(Xc); tars.append(yc); total += len(Xc)\n",
        "        else:\n",
        "            feats.append(Xc); tars.append(yc)\n",
        "    if len(feats)==0:\n",
        "        raise ValueError(\"No data loaded - check CSV path and columns.\")\n",
        "    X = pd.concat(feats, ignore_index=True)\n",
        "    y = pd.concat(tars, ignore_index=True)\n",
        "    print(f\"Loaded {len(X)} rows from train (sample_size={sample_size}).\")\n",
        "    return X, y\n",
        "\n",
        "print(\"Loading training sample (this may take some minutes)...\")\n",
        "X_full, y_full = load_sampled_dataframe(CSV_TRAIN_PATH)\n",
        "X_train_df, X_val_df, y_train_s, y_val_s = train_test_split(X_full, y_full, test_size=TEST_SPLIT, random_state=RANDOM_SEED)\n",
        "print(\"Train rows:\", len(X_train_df), \"Val rows:\", len(X_val_df))\n"
      ],
      "metadata": {
        "id": "KjZObMltNoXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 6: Scaling + tf.data datasets\n",
        "num_cols = X_train_df.columns.tolist()\n",
        "scaler = StandardScaler(); scaler.fit(X_train_df[num_cols])\n",
        "X_train = scaler.transform(X_train_df[num_cols]).astype(np.float32)\n",
        "X_val   = scaler.transform(X_val_df[num_cols]).astype(np.float32)\n",
        "y_train = y_train_s.values.astype(np.float32)\n",
        "y_val   = y_val_s.values.astype(np.float32)\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(100000, seed=RANDOM_SEED).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "val_ds   = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Save scaler for later testing/inference\n",
        "print(len(X_train))\n",
        "import joblib\n",
        "joblib.dump(scaler, os.path.join(RESULTS_DIR, f\"scaler_{DEVICE}.joblib\"))\n",
        "print(\"Saved scaler to Drive.\")\n"
      ],
      "metadata": {
        "id": "qcw5ydblNqtO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 7: Model builder + epoch timer\n",
        "def build_model(input_dim, size=\"small\"):\n",
        "    inp = keras.Input(shape=(input_dim,))\n",
        "    if size==\"small\":\n",
        "        x = layers.Dense(64, activation='relu')(inp)\n",
        "        x = layers.Dense(32, activation='relu')(x)\n",
        "    elif size==\"medium\":\n",
        "        x = layers.Dense(128, activation='relu')(inp)\n",
        "        x = layers.Dense(128, activation='relu')(x)\n",
        "        x = layers.Dense(64, activation='relu')(x)\n",
        "    else: # large\n",
        "        x = layers.Dense(256, activation='relu')(inp)\n",
        "        x = layers.Dense(128, activation='relu')(x)\n",
        "        x = layers.Dense(64, activation='relu')(x)\n",
        "        x = layers.Dense(32, activation='relu')(x)\n",
        "    out = layers.Dense(1, activation='linear')(x)\n",
        "    model = keras.Model(inp, out)\n",
        "    model.compile(optimizer=keras.optimizers.Adam(1e-3),\n",
        "                  loss='mse',\n",
        "                  metrics=[keras.metrics.RootMeanSquaredError(name='rmse'),\n",
        "                           keras.metrics.MeanAbsoluteError(name='mae')])\n",
        "    return model\n",
        "\n",
        "class EpochTimer(callbacks.Callback):\n",
        "    def on_train_begin(self, logs=None):\n",
        "        self.epoch_times=[]\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        self._t0 = time.time()\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        self.epoch_times.append(time.time()-self._t0)\n"
      ],
      "metadata": {
        "id": "oN9uQV9PNtcH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 8: Train models (small/medium/large), save models & metrics\n",
        "sizes = ['small','medium','large']\n",
        "histories = {}\n",
        "epoch_times_all = {}\n",
        "metrics_summary = []\n",
        "\n",
        "for size in sizes:\n",
        "    print(f\"\\n--- Training {size} on {DEVICE} ---\")\n",
        "    with strategy.scope():\n",
        "        model = build_model(X_train.shape[1], size=size)\n",
        "    model.summary()\n",
        "    timer_cb = EpochTimer()\n",
        "    early = callbacks.EarlyStopping(monitor='val_rmse', patience=5, restore_best_weights=True)\n",
        "    start_time = time.time()\n",
        "    hist = model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS, callbacks=[timer_cb, early], verbose=2)\n",
        "    total_train_time = time.time() - start_time\n",
        "\n",
        "    histories[size] = hist.history\n",
        "    epoch_times_all[size] = timer_cb.epoch_times\n",
        "    epochs_trained = len(timer_cb.epoch_times)\n",
        "    avg_epoch_time = float(np.mean(timer_cb.epoch_times)) if epochs_trained>0 else None\n",
        "\n",
        "    # Evaluate on validation arrays (fast)\n",
        "    preds_val = model.predict(X_val, batch_size=BATCH_SIZE).ravel()\n",
        "    rmse = math.sqrt(mean_squared_error(y_val, preds_val))\n",
        "    mae  = float(np.mean(np.abs(y_val - preds_val)))\n",
        "    r2   = float(r2_score(y_val, preds_val))\n",
        "\n",
        "    # Save model and metrics\n",
        "    model_path = os.path.join(RESULTS_DIR, f\"model_{DEVICE}_{size}.h5\")\n",
        "    model.save(model_path)\n",
        "    np.savez(os.path.join(RESULTS_DIR, f\"metrics_{DEVICE}_{size}.npz\"),\n",
        "             rmse=rmse, mae=mae, r2=r2, preds=preds_val, y_val=y_val)\n",
        "    metrics_summary.append({\n",
        "        'device': DEVICE, 'size': size, 'epochs_trained': epochs_trained,\n",
        "        'avg_epoch_time_s': avg_epoch_time, 'total_train_time_s': float(total_train_time),\n",
        "        'final_val_rmse': float(rmse), 'final_val_mae': float(mae), 'final_val_r2': float(r2)\n",
        "    })\n",
        "    print(f\"{size} done: epochs={epochs_trained}, avg_epoch_s={avg_epoch_time:.3f}, total_s={total_train_time:.1f}, rmse={rmse:.4f}, r2={r2:.4f}\")\n",
        "\n",
        "# Save metrics summary\n",
        "metrics_df = pd.DataFrame(metrics_summary)\n",
        "metrics_df.to_csv(os.path.join(RESULTS_DIR, f\"metrics_summary_{DEVICE}.csv\"), index=False)\n",
        "print(\"Saved metrics summary CSV.\")\n"
      ],
      "metadata": {
        "id": "gRK4E7snNvfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 9: Plotting (epoch times, loss/RMSE curves, summary)\n",
        "plt.figure(figsize=(10,6))\n",
        "for size in sizes:\n",
        "    times = epoch_times_all.get(size, [])\n",
        "    if len(times)>0:\n",
        "        plt.plot(range(1,len(times)+1), times, marker='o', label=size)\n",
        "plt.xlabel(\"Epoch\"); plt.ylabel(\"Epoch time (s)\"); plt.title(f\"Epoch time per epoch ({DEVICE})\")\n",
        "plt.legend(); plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(RESULTS_DIR, f\"epoch_time_{DEVICE}.png\")); plt.show()\n",
        "\n",
        "for size in sizes:\n",
        "    h = histories.get(size, {})\n",
        "    if not h: continue\n",
        "    ep = range(1, len(h.get('loss',[])) + 1)\n",
        "    plt.figure(figsize=(12,4))\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.plot(ep, h.get('loss',[]), label='train_loss'); plt.plot(ep, h.get('val_loss',[]), label='val_loss')\n",
        "    plt.title(f\"{size} Loss ({DEVICE})\"); plt.legend()\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.plot(ep, h.get('rmse',[]), label='train_rmse'); plt.plot(ep, h.get('val_rmse',[]), label='val_rmse')\n",
        "    plt.title(f\"{size} RMSE ({DEVICE})\"); plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(RESULTS_DIR, f\"loss_rmse_{DEVICE}_{size}.png\")); plt.show()\n",
        "\n",
        "# Summary bar charts\n",
        "avg_epoch_times = [m['avg_epoch_time_s'] for m in metrics_summary]\n",
        "final_rmse = [m['final_val_rmse'] for m in metrics_summary]\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.subplot(1,2,1); plt.bar(sizes, avg_epoch_times); plt.title('Avg epoch time (s)'); plt.ylabel('s')\n",
        "plt.subplot(1,2,2); plt.bar(sizes, final_rmse); plt.title('Final val RMSE'); plt.ylabel('RMSE')\n",
        "plt.tight_layout(); plt.savefig(os.path.join(RESULTS_DIR, f\"summary_bar_{DEVICE}.png\")); plt.show()\n",
        "print(\"Saved all plots to Drive.\")\n"
      ],
      "metadata": {
        "id": "-b-i8HskNywY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "#  FINAL FULL TEST PREDICTION CODE (PRINT LOOP INCLUDED)\n",
        "# ============================================================\n",
        "\n",
        "# 1. Feature list (used by BOTH train + test)\n",
        "FEATURE_COLUMNS = [\n",
        "    'hour','dow','month',\n",
        "    'pickup_longitude','pickup_latitude',\n",
        "    'dropoff_longitude','dropoff_latitude',\n",
        "    'distance_km','abs_lon_diff','abs_lat_diff',\n",
        "    'passenger_count'\n",
        "]\n",
        "\n",
        "\n",
        "# 2. Final safe test prediction function\n",
        "def predict_test_for_model(model_path, scaler, size_tag):\n",
        "    print(f\"\\n Predicting test for model size: {size_tag}\")\n",
        "\n",
        "    # load model\n",
        "    model = keras.models.load_model(model_path, compile=False)\n",
        "\n",
        "    # output path in Drive\n",
        "    out_file = os.path.join(RESULTS_DIR, f\"predictions_{DEVICE}_{size_tag}.csv\")\n",
        "\n",
        "    # stream test.csv in chunks\n",
        "    reader = pd.read_csv(CSV_TEST_PATH, chunksize=CHUNK_SIZE, iterator=True)\n",
        "    header_written = False\n",
        "    total_rows = 0\n",
        "\n",
        "    for chunk_idx, chunk in enumerate(reader, start=1):\n",
        "\n",
        "        # detect ID column safely\n",
        "        if 'key' in chunk.columns:\n",
        "            ids = chunk['key']\n",
        "        elif 'id' in chunk.columns:\n",
        "            ids = chunk['id']\n",
        "        else:\n",
        "            ids = pd.Series(np.arange(len(chunk)))\n",
        "\n",
        "        # preprocess WITHOUT filtering\n",
        "        Xc, _ = preprocess_df(chunk)\n",
        "\n",
        "        # **CRITICAL LINE** – select ONLY model features\n",
        "        Xc = Xc[FEATURE_COLUMNS]\n",
        "\n",
        "        # scale\n",
        "        Xc_sc = scaler.transform(Xc).astype(np.float32)\n",
        "\n",
        "        # predict\n",
        "        preds = model.predict(Xc_sc, batch_size=2048, verbose=0).ravel()\n",
        "\n",
        "        # limit ids length\n",
        "        ids_aligned = ids.iloc[:len(preds)].values\n",
        "\n",
        "        # create dataframe\n",
        "        out_df = pd.DataFrame({\n",
        "            'key': ids_aligned,\n",
        "            'predicted_fare': preds\n",
        "        })\n",
        "\n",
        "        # write to file\n",
        "        if not header_written:\n",
        "            out_df.to_csv(out_file, index=False, mode='w')\n",
        "            header_written = True\n",
        "        else:\n",
        "            out_df.to_csv(out_file, index=False, header=False, mode='a')\n",
        "\n",
        "        total_rows += len(preds)\n",
        "        print(f\"   Chunk {chunk_idx}: wrote {len(preds)} rows (total = {total_rows})\")\n",
        "\n",
        "    print(f\"\\n Saved: {out_file}\")\n",
        "    print(f\" Total predictions generated: {total_rows}\")\n",
        "\n",
        "    return out_file\n",
        "\n",
        "\n",
        "\n",
        "# 3. === RUN FOR ALL MODEL SIZES (prints output) ===\n",
        "\n",
        "print(\" Starting prediction on TEST.csv ...\")\n",
        "\n",
        "for m in metrics_summary:\n",
        "    model_size = m['size']\n",
        "    model_file = os.path.join(RESULTS_DIR, f\"model_{DEVICE}_{model_size}.h5\")\n",
        "    predict_test_for_model(model_file, scaler, model_size)\n",
        "\n",
        "print(\"\\n All test predictions completed successfully!\")\n"
      ],
      "metadata": {
        "id": "kGcEoaI6N0vF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "#  CELL 12: Accuracy Metrics + Plots for ALL model sizes\n",
        "# ==========================================================\n",
        "\n",
        "from sklearn.metrics import r2_score, mean_absolute_percentage_error\n",
        "\n",
        "print(\"Generating accuracy metrics for all model sizes...\\n\")\n",
        "\n",
        "for m in metrics_summary:\n",
        "    size_tag = m['size']\n",
        "\n",
        "    metrics_path = os.path.join(RESULTS_DIR, f\"metrics_{DEVICE}_{size_tag}.npz\")\n",
        "    if not os.path.exists(metrics_path):\n",
        "        print(f\"Metrics file missing for model size: {size_tag}. Skipping.\")\n",
        "        continue\n",
        "\n",
        "    data = np.load(metrics_path, allow_pickle=True)\n",
        "    preds = data['preds']\n",
        "    yval  = data['y_val']\n",
        "\n",
        "    rmse = np.sqrt(np.mean((yval - preds)**2))\n",
        "    r2 = r2_score(yval, preds)\n",
        "    mape = mean_absolute_percentage_error(yval, preds) * 100\n",
        "\n",
        "    print(f\"\\n===== Model: {DEVICE}-{size_tag} =====\")\n",
        "    print(f\"RMSE  : {rmse:.4f}\")\n",
        "    print(f\"R²    : {r2:.4f}\")\n",
        "    print(f\"MAPE  : {mape:.2f}%\")\n",
        "    print(\"========================================\\n\")\n",
        "\n",
        "    # Pred vs Actual\n",
        "    plt.figure(figsize=(8,8))\n",
        "    plt.scatter(yval, preds, s=2, alpha=0.25)\n",
        "    mx = max(yval.max(), preds.max())\n",
        "    plt.plot([0, mx], [0, mx], 'r--', linewidth=2)\n",
        "    plt.xlabel('Actual Fare', fontsize=12)\n",
        "    plt.ylabel('Predicted Fare', fontsize=12)\n",
        "    plt.title(f'Pred vs Actual ({DEVICE}-{size_tag})', fontsize=15)\n",
        "    plt.grid(True, alpha=0.2)\n",
        "    plt.ylim(0, 100)\n",
        "\n",
        "    out1 = os.path.join(RESULTS_DIR, f\"pred_vs_actual_{DEVICE}_{size_tag}.png\")\n",
        "    plt.savefig(out1, dpi=120, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    # Residual distribution\n",
        "    resid = yval - preds\n",
        "    plt.figure(figsize=(12,4))\n",
        "    plt.hist(resid, bins=80, color='steelblue', edgecolor='black', alpha=0.8)\n",
        "    plt.title(f'Residuals ({DEVICE}-{size_tag})', fontsize=15)\n",
        "    plt.xlabel('Residual (Actual - Predicted)', fontsize=12)\n",
        "    plt.ylabel('Frequency', fontsize=12)\n",
        "    plt.grid(True, alpha=0.2)\n",
        "\n",
        "    out2 = os.path.join(RESULTS_DIR, f\"residuals_{DEVICE}_{size_tag}.png\")\n",
        "    plt.savefig(out2, dpi=120, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Saved plots:\\n  - {out1}\\n  - {out2}\\n\")\n",
        "\n",
        "print(\"\\nCompleted accuracy reporting for all models.\")\n"
      ],
      "metadata": {
        "id": "yDRyHR55N2eq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 12: Final summary\n",
        "metrics_df = pd.read_csv(os.path.join(RESULTS_DIR, f\"metrics_summary_{DEVICE}.csv\"))\n",
        "print(metrics_df)\n",
        "print(\"Notebook finished for device:\", DEVICE)\n"
      ],
      "metadata": {
        "id": "wQgZRfSpN4b9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}